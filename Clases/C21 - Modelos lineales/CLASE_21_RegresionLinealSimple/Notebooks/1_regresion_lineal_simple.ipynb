{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://www.digitalhouse.com/ar/logo-DH.png\" width=\"400\" height=\"200\" align='right'>](http://digitalhouse.com.ar/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Wa2YIkX0szy"
   },
   "source": [
    "# Regresión Lineal con scikit-learn y statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDCPMw710sz1"
   },
   "source": [
    "## Resumen\n",
    "<div id=\"caja4\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:right;width: 15%;\"><img src=\"../../../common/icons/en_resumen.png\" style=\"align:right\"/> </div>\n",
    "  <div style=\"float:right;width: 85%;\"><label></label></div>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Hoy vamos a investigar un dataset clásico en el mundo de data science (DS), el dataset de propiedades de la ciudad de  Boston. \n",
    "\n",
    "En particular aplicaremos la regresion lineal a un problema inmobiliario. Sin embargo, descubriremos que esta técnica puede ser muy útil en otras areas como: marketing, finanzas, biología, petroquímica, etc. A lo largo de esta notebook vamos a usar dos librerías (o paquetes) diferentes, para los que pueden ver ejemplos en la documentación oficial.\n",
    "\n",
    "* statsmodels -- [docs regresión lineal](http://statsmodels.sourceforge.net/devel/examples/#regression)\n",
    "* scikit-learn -- [docs regresión lineal](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4r9z-_-t0sz5"
   },
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Ya nos hemos familizarizado bastante con scikit-learn, e iremos viendo la potencia de la misma. Sin embargo también debemos saber que  la librería incluye algunos datasets para testear y practicar los algoritmos que tiene implementado. El listado de los datasets que podemos encontrar los podes ver [aquí](https://scikit-learn.org/stable/datasets/index.html). \n",
    "\n",
    "Para cargar el dataset con el que vamos a trabajar hoy simplemente hay que importarlo desde sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos algunas librerias para graficar.\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdBq2lZi0sz6"
   },
   "outputs": [],
   "source": [
    "# importamos el modelo lineal y algunas funciones para calcular la bondad de ajuste.\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoPlnDJr0s0B"
   },
   "source": [
    "## 2. Conociendo el formato de los datsets de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ionatan\\anaconda3\\envs\\DH\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Para cargar el dataset lo importamos desde scikit-learn.\n",
    "from sklearn import datasets\n",
    "data = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mType:\u001b[0m        module\n",
      "\u001b[1;31mString form:\u001b[0m <module 'sklearn.datasets' from 'c:\\\\Users\\\\Ionatan\\\\anaconda3\\\\envs\\\\DH\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\__init__.py'>\n",
      "\u001b[1;31mFile:\u001b[0m        c:\\users\\ionatan\\anaconda3\\envs\\dh\\lib\\site-packages\\sklearn\\datasets\\__init__.py\n",
      "\u001b[1;31mSource:\u001b[0m     \n",
      "\u001b[1;34m\"\"\"\n",
      "The :mod:`sklearn.datasets` module includes utilities to load datasets,\n",
      "including methods to load and fetch popular reference datasets. It also\n",
      "features some artificial data generators.\n",
      "\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_breast_cancer\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_diabetes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_digits\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_files\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_linnerud\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_sample_images\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_sample_image\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_wine\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_data_home\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclear_data_home\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_covtype\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_covtype\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_kddcup99\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_kddcup99\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lfw\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_lfw_pairs\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lfw\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_lfw_people\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_twenty_newsgroups\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_twenty_newsgroups\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_20newsgroups_vectorized\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_openml\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_multilabel_classification\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_hastie_10_2\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_regression\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_moons\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_circles\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_friedman1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_friedman2\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_friedman3\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_low_rank_matrix\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_sparse_coded_signal\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_sparse_uncorrelated\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_spd_matrix\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_swiss_roll\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_s_curve\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_sparse_spd_matrix\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_gaussian_quantiles\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_biclusters\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_samples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_checkerboard\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_svmlight_format_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_svmlight_file\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_svmlight_format_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_svmlight_files\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_svmlight_format_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdump_svmlight_file\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_olivetti_faces\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_olivetti_faces\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_species_distributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_species_distributions\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_california_housing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_rcv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_rcv1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"clear_data_home\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"dump_svmlight_file\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_20newsgroups\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_20newsgroups_vectorized\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_lfw_pairs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_lfw_people\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_olivetti_faces\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_species_distributions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_california_housing\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_covtype\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_rcv1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_kddcup99\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"fetch_openml\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"get_data_home\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_boston\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_diabetes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_digits\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_files\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_iris\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_breast_cancer\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_linnerud\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_sample_image\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_sample_images\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_svmlight_file\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_svmlight_files\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"load_wine\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_biclusters\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_blobs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_circles\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_classification\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_checkerboard\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_friedman1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_friedman2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_friedman3\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_gaussian_quantiles\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_hastie_10_2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_low_rank_matrix\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_moons\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_multilabel_classification\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_regression\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_s_curve\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_sparse_coded_signal\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_sparse_spd_matrix\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_sparse_uncorrelated\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_spd_matrix\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"make_swiss_roll\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# imprimimos la ayuda para ver todos los datasets dispoibles.\n",
    "datasets??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para echarles un vistazo podemos ver con el atributo DESCR la descripcion del dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset lista 14 atributos que describen hogares de boston. Como dice la descripción el valor medio es el atributo que habitualmente se utiliza como variable objetivo. En nuestro caso mas sencillo es el atributo que intentaremos predecir a partir de otras variables explicativas. Cada instancia del dataframe describe un área suburbana o municipio de Boston ( Boston Standard Metropolitan Statistical Area (SMSA)) en 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TS2ruNp0s0D"
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Un Bunch es un diccionario de Python dictionary que provee acceso utilizando atributos. Un Bunch es una subclase de dict y soporta todos los métodos de un dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKvUJaZc0s0I"
   },
   "outputs": [],
   "source": [
    "#Dentro del Bunch podemos obtener diferentes atributos de nuestro dataset.\n",
    "# Los nombres de las columnas \n",
    "print (data.feature_names)\n",
    "# Los predictores o variables independientes.\n",
    "print (data.data[0])\n",
    "# La variable objetivo o variable dependiente.\n",
    "print (data.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmruwKMB0s0Q"
   },
   "source": [
    "Como pueden ver, Scikit-learn ya separó el precio medio  de las casas del resto de las variables. El atributo target u objetivo (data.target) es nuestra variable dependiente intentaremos predecir a partir de los demás.\n",
    "\n",
    "## 3. Estimando el modelo de regresión lineal\n",
    "\n",
    "Primero, pongamos los datos en un data frame y asegurémonos de que esté todo cargado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKbXlsV90s0S"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEDV\n",
       "0  24.0\n",
       "1  21.6\n",
       "2  34.7\n",
       "3  33.4\n",
       "4  36.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Ponemos el target (precio de las casas -- MEDV) en otro DataFrame\n",
    "targets = pd.DataFrame(data.target, columns=[\"MEDV\"])\n",
    "\n",
    "# Miremos las primeras filas de datos\n",
    "display (df.head())\n",
    "display (targets.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9ZUaUYF0s0Y"
   },
   "source": [
    "El primer ejercicio podria ser: Seleccionar variables una por una y ver su relación con la variable objetivo.\n",
    "\n",
    "* Identifiquemos visualmente algunas variables que parezcan relacionadas al precio. Por ejemplo: RM and LSTAT. \n",
    "\n",
    "* Hagamos un análisis por separado y luego juntas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relación entre RM y MEDV\n",
    "\n",
    " Generamos las matrices de variables explicativas o independientes y el target.\n",
    " \n",
    " Primero seleccionamos como variable explicativa a RM como numero promedio de habitaciones.\n",
    " \n",
    " \n",
    " ### Para Pensar...\n",
    " \n",
    " <div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>Tiene sentido que exista una relacion lineal entre el numero promedio de habitaciones y el precio promedio?.\n",
    "</label></div>\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "put9dBHF0s0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercepto=   -34.670620776438554\n",
      "RM=   [9.10210898]\n",
      "R2_train=   0.48352545599133423\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos la variable predictora y la objetivo.\n",
    "X = df[[\"RM\"]]\n",
    "y = targets[\"MEDV\"]\n",
    "\n",
    "# Importamos, Instanciamos, Fiteamos, etc..\n",
    "\n",
    "# Instanciamos el modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Fiteamos el modelo sobre los vectores X e y.\n",
    "model = lm.fit(X, y)\n",
    "#\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', model.intercept_)\n",
    "print ('RM=', ' ', model.coef_)\n",
    "# imprimos la metrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2_train=', ' ', model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtT_4KxK0s0e"
   },
   "outputs": [],
   "source": [
    "# Generamos una función que resume los coeficientes, el intercepto y el R2\n",
    "# \"model\" = objeto con el modelo\n",
    "# \"X\" = matrix de variables independientes\n",
    "\n",
    "def sum_mod(model, X):\n",
    "    a = pd.DataFrame(model.coef_ , X.columns.values)\n",
    "    a = a.append(pd.DataFrame([model.intercept_, model.score(X, y)], index=['Intecept','R2']))\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oh84xSwc0s0m"
   },
   "outputs": [],
   "source": [
    "# Graficamos la variable X contra la variable Y\n",
    "plt.scatter(X, y, s=30, c='black', marker='+', zorder=10)\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.title('Relación entre RM y MEDV')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos el modelo\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de MEDV usando RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.title('Comparación entre el modelo y los valores reales de MEDV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6708oFio0s0t"
   },
   "outputs": [],
   "source": [
    "print (\"EMC:\", mean_squared_error(y, predictions)) # error medio cuadrático\n",
    "sum_mod(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRX6DzFn0s0w"
   },
   "source": [
    "* ¿Qué pueden decir al comparar los dos gráficos? ¿Cómo interpretan el último gráfico ? ¿Qué les dice acerca del modelo? ¿Qué pueden decir acerca de la relación entre RM y MEDV? \n",
    "\n",
    "* Repitamos ahora lo anterior pero usando otra variable...\n",
    "\n",
    "\n",
    "El primer gráfico tiene como objetivo evaluar si existe algún tipo de relacion lineal entre la variable explicativa y la variable objetivo. En particular con estas variables se observa que hay cierta correlación entre ellas, puesto que cuando el número de Habitaciones promedio aumenta, el precio medio de la zona también aumenta, lo cual tiene cierto sentido. \n",
    " \n",
    " El segundo gráfico es la comparación entre el **valor real observado** vs el **valor predicho** por nuestro modelo. Es decir obtuvimos cuál es la relación entre la variable RM y MEDV a través de un vector de coeficientes y un intercepto.\n",
    " \n",
    " Como se interpreta el **EMC** porque usamos esa metrica? existe alguna mejor que otra? Que es el R2, puede dar negativo?. \n",
    " \n",
    " Algunos recursos para repasar estos [conceptos](https://towardsdatascience.com/regression-an-explanation-of-regression-metrics-and-what-can-go-wrong-a39a9793d914)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relación entre LSTAT y MEDV\n",
    "\n",
    "De manera muy similar al ejercicio anterior, observamos si existe relación entre la variable LSTAT (porcentaje con menos status o menor poder adquisitivo de la población) y el precio promedio (MEDV). Esta variable (LSTAT) podría tener alguna relación inversa con la variable objetivo (precios), puesto que podemos inferir que mientras mayor es el porcentaje de la población que tiene menor poder adquisitivo, más baratas (en promedio) deberían ser las casas. Por lo que esperamos una relación inversa entre el índice LSTAT y la variable objetivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHCwncX70s0z"
   },
   "outputs": [],
   "source": [
    "# Instanciamos el nuevo modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "#  Seleccionamos la variable a testear.\n",
    "X = df[[\"LSTAT\"]]\n",
    "y = targets[\"MEDV\"]\n",
    "\n",
    "# Fiteamos y realizamos las predicciones.\n",
    "model = lm.fit(X, y)\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "# Graficamos la variable X contra la variable Y\n",
    "plt.scatter(X, y, s=30, c='black', marker='+', zorder=10)\n",
    "plt.xlabel(\"LSTAT\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.title('Relación entre LSTAT y MEDV')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos el modelo\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='o', zorder=10)\n",
    "plt.xlabel(\"Predicciones de MEDV usando LSTAT\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.title('Comparación entre el modelo y los valores reales de MEDV')\n",
    "plt.show()\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "sum_mod(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "natZxD8v0s06"
   },
   "source": [
    "* ¿Qué pueden decir al comparar éste modelo y el anterior? \n",
    "\n",
    "Como anticipamos el coeficiente beta de la variable LSTAT es negativo. Cuál es la interpretación del intercepto?.\n",
    "\n",
    "* Estimemos, ahora, un modelo usando las dos variables anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model lineal con dos variables. LSTAT y RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfmi13PL0s08"
   },
   "outputs": [],
   "source": [
    "# Instancio el modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "X = df[[\"RM\", \"LSTAT\"]]\n",
    "y = targets[\"MEDV\"]\n",
    "\n",
    "# Fiteo el modelo y hago las predicciones.\n",
    "model = lm.fit(X, y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Graficamos el modelo\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de MEDV usando RM y LSTAT\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "prevMSE = mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mod(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeI0a48X0s0_"
   },
   "source": [
    "Al utilizar las dos variables que pasa con el ajuste de la regresión?. Como es la interpretación de los coeficientes?\n",
    "\n",
    "## Comparando los modelos\n",
    "\n",
    "Un modelo perfecto se vería como una línea recta a 45 grados como la que vemos en gris. Ya veremos cómo cuantificar la bondad de ajuste pronto.\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "\n",
    "<div id=\"caja3\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/en_accion.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>Ajustar el modelo usando TODAS las variables, usando X = df. Esto mejora el ajuste? (comparar el EMC).</label></div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4oSehd50s1B"
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "#X = df[['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']]\n",
    "\n",
    "#Otra opción para definir X\n",
    "X = df[list(df.columns.values)]\n",
    "\n",
    "y = targets[\"MEDV\"]\n",
    "\n",
    "model = lm.fit(X, y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Graficamos el modelo\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de MEDV usando todas las variables\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (\"¿Mejora?: \", mean_squared_error(y, predictions) < prevMSE)\n",
    "\n",
    "print (sum_mod(model, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Conclusiones:</b> \n",
    "    En la primera aproximación evaluamos variables explicativas como RM y LSTAT. De cada variable relevada el modelo de regresión lineal muestra un R cuadrado (R2) de 0.48 y 0.54 respectivamente. Al combinar ambas en un modelo de regresion multiple el R2 aumenta a 0.63 con un EMC de 30.   \n",
    "    \n",
    "Por último ejercicio incluye agregar todas las variables del dataset para generar y ajustar  a un modelo multiple con 13 variables explicativas. En consecuencia obtenemos un modelo con un R2 de 0.74 y un EMC de 21   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYd8jNFE0s1F"
   },
   "source": [
    "## Introducción a Statsmodels\n",
    "\n",
    "### Statsmodels vs sklearn. \n",
    "Si ya estamos familiarizados con scikit-learn porque usar otra libreria?. Como vimos en clase hay muchos supuestos detrás de un simple modelo regresión lineal. Por ende si deseamos un análisis estadístico completo  de los p-values de los coeficientes, desvío estándar, errores de cada parámetro, test-t o algún otro, necesitaremos mudarnos de librería.  \n",
    "\n",
    "\n",
    "Veamos ahora cómo se usa otra librería popular para realizar regresiones como Statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jL-r0_BH0s1N"
   },
   "outputs": [],
   "source": [
    "# Importamos la api.\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# De manera análoga a la vista en el primer ejercicio, definimos el vector de variables con la primer variable RM.\n",
    "X = df[[\"RM\"]]\n",
    "y = targets[[\"MEDV\"]]\n",
    "\n",
    "# Tenemos que agregar explícitamente a una constante:\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.plot(y,y, '-.', c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos el MSE y un resumen del modelo\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que podemos decir del p-value para la variable RM. \n",
    "\n",
    "\n",
    "* ¿Cómo fue la performance de esta libreria (comparar ECM con sklearn)? \n",
    "* ¿Que puede decirse del coeficiente de RM?¿Es significativo?¿Que significa esto?\n",
    "* ¿ Que es el 'R ajustado'? ¿Para que sirve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "\n",
    "<div id=\"caja8\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_saber_mas.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label></label></div>\n",
    "</div>\n",
    "\n",
    "\n",
    "Recursos extra: \n",
    "* Si queres entender de manera interactiva las regresiones lineales no dejes de ver este [recurso](http://setosa.io/ev/ordinary-least-squares-regression).\n",
    "\n",
    "* Repaso de conceptos: [R ajustado:](https://www.statisticshowto.datasciencecentral.com/adjusted-r2/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1.PRACTICA_GUIADA_Scikit_Learn_Stats_Models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "93b1ad9c150e9c4fa5781c5a37e00b91f3d8cfbe17fc5b5e6277144ed0216a69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
