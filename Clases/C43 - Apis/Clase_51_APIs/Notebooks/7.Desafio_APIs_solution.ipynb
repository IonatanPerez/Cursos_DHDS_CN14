{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs - Práctica independiente\n",
    "\n",
    "\n",
    "#### En esta práctica independiente vamos a utilizar la práctica 3 (Mercadolibre) para generar un dataset y efectuar una predicción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar esta práctica, ejecuten la tercera práctica guiada, utilizando una búsqueda que les resulte de interés para generar el DataFrame. \n",
    "\n",
    "Pueden elegir como target regresionar el precio de la publicación, o la cantidad de unidades vendidas, y usar el target que no seleccionen como feature en su modelo.\n",
    "\n",
    "**NOTA:** No pidan más de 10000 datos totales para no tener conflictos con los límites de la API, no pidan menos de 500 para poder modelar de forma sencilla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importamos los datos\n",
    "\n",
    "Vamos a usar esta celda con un input para poder ingresar manualmente la búsqueda que hicimos en la práctica anterior. La búsqueda puede ser cualquier producto que les resulte interesante, sólo recuerden usar el mismo que usaron para generar el dataset!\n",
    "\n",
    "Ejemplo: iphone 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from base import ColumnSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del DataFrame\n",
    "search = input(\"Inserten la búsqueda utilizada para generar el DataFrame:\")\n",
    "df = pd.read_csv(f\"../Data/{search.lower().replace(' ', '_')}_meli.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identificamos columnas numéricas y categóricas\n",
    "\n",
    "El objetivo de este ejercicio es seleccionar columnas categóricas y numéricas. Vamos a identificarlas, de manera de poder armar un preprocesamiento acorde para cada una. **BONUS:** Identificar columnas de texto y pensar una solución que incluya text mining para nuestro pipeline final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar, separemos la variable target, para evitar confusiones. Si en el histograma del ejercicio anterior vimos algún valor extremo, es un buen momento para eliminarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la mitad del percentil superior de precio.\n",
    "df = df.query(\"price <= @df.price.quantile(.995)\")  # Si bien los iPhones son costosos,\n",
    "                                                    # 10 millones de pesos parece excesivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.price\n",
    "X = df.drop(\"price\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a eliminar columnas que no parecen tener demasiada información, pero que escaparon a nuestra limpieza preliminar anterior. Si su búsqueda **no** tiene estas columnas, esta celda simplemente imprimirá un mensaje. Si alguna de ellas les parece importante en el contexto de su modelo, pueden simplemente removerlas de la lista `cols_to_remove`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = [\"id\", \"listing_type_id\", \"seller__real_estate_agency\", \"shipping__logistic_type\", \"magical_properties\"]\n",
    "\n",
    "for col in cols_to_remove:\n",
    "    try:\n",
    "        X = X.drop(col, axis=1)\n",
    "        print(f\"La columna {col} fue removida exitosamente.\")\n",
    "    except:\n",
    "        print(f\"La columna {col} no se encuentra en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación removeremos las columnas de tags, que deberían tratarse de manera especial, así como la de Título, que es de texto. Esto **NO** es lo más correcto para mejorar la predicción, se hará simplemente para poder iterar soluciones más rápidamente. Sugerimos enfáticamente que las agreguen a su solución final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\"title\", *[col for col in df.columns if \"tags\" in col]]\n",
    "for col in text_cols:\n",
    "    try:\n",
    "        X = X.drop(col, axis=1)\n",
    "        print(f\"La columna {col} fue removida exitosamente.\")\n",
    "    except:\n",
    "        print(f\"La columna {col} no se encuentra en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:, X.dtypes == \"object\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las columnas de tipo object parecen ser categóricas. Revisemos los Integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:, X.dtypes == \"int\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seller__id es una columna int, pero que claramente alude a una categoría. Vamos a intentar determinar si vale la pena convertirla en variable categórica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.seller__id.nunique() / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que tenemos varios vendedores repetidos. Tenemos muchas variables de vendedor para poder prescindir del id, con lo que, si bien la marca puede ser importante, confiaremos en que esté latente en la información numérica del vendedor.\n",
    "\n",
    "**BONUS:** intentar determinar si esta decisión es correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_cols = X.loc[:, X.dtypes == \"object\"].columns\n",
    "num_cols = X.loc[:, (X.dtypes == \"int\") | (X.dtypes == \"float\")].columns\n",
    "# Elimino la columna si sobrevive chequeos previos, si no, no hay problema.\n",
    "num_cols = [col for col in num_cols if col != \"seller__id\"]\n",
    "\n",
    "print(\"Columnas Categóricas:\", categ_cols)\n",
    "print(\"Columnas Numéricas:\", num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armemos ahora nuestras particiones de train y test, para poder trabajar más sencillamente a la hora de probar estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Planteamos la FeatureUnion para nuestras distintas variables\n",
    "\n",
    "Armemos un Pipeline de preprocesamiento para cada tipo de variable, y usemos FeatureUnion para unir los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline de variables Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_num = Pipeline(\n",
    "    [\n",
    "        (\"select\", ColumnSelector(num_cols)),\n",
    "        (\"impute\", SimpleImputer()),  # Por default imputa con media.\n",
    "        (\"scale\", StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline de variables Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cat = Pipeline(\n",
    "    [\n",
    "        (\"select\", ColumnSelector(categ_cols)),\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),  # Utilizo la moda como estrategia.\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = FeatureUnion(\n",
    "    [\n",
    "        (\"numeric\", pipe_num),\n",
    "        (\"categoric\", pipe_cat),\n",
    "        # OPCIONAL: \"tag_features\" y \"text_features\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Armamos nuestro Pipeline\n",
    "\n",
    "Generemos un Pipeline que tome como paso el FeatureUnion del ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", union),\n",
    "        (\"rgr\", None)  # Paso previsto para nuestros posibles regresores.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Utilizamos Gridsearch para tunear hiperparámetros\n",
    "Vamos a terminar esta práctica haciendo un tuneo para el Pipeline final. Intentemos maximizar nuestro $R^2$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"rgr\": [ElasticNet()], \"rgr__alpha\": [np.logspace(-3, 2, 7)], \"rgr__l1_ratio\": [0.2, 0.5, 0.9]},\n",
    "    {\n",
    "        \"rgr\": [RandomForestRegressor()],\n",
    "        \"rgr__n_estimators\": [200, 500],\n",
    "        \"rgr__min_samples_leaf\": np.arange(1, 11, 2),\n",
    "        \"rgr__max_depth\": [None, 1, 2, 3]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede llevar un par de minutos.\n",
    "grid = GridSearchCV(full_pipe, param_grid, scoring=\"r2\", n_jobs=-1, verbose=10)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los resultados de nuestro mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con estas columnas, este parece ser el mejor resultado que podemos lograr. Qué podríamos hacer para mejorarlo?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
