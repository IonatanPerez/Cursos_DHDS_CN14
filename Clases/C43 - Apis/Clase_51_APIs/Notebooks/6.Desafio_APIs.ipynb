{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs - Práctica independiente\n",
    "\n",
    "\n",
    "#### En esta práctica independiente vamos a utilizar la práctica 3 (Mercadolibre) para generar un dataset y efectuar una predicción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar esta práctica, ejecuten la tercera práctica guiada, utilizando una búsqueda que les resulte de interés para generar el DataFrame. \n",
    "\n",
    "Pueden elegir como target regresionar el precio de la publicación, o la cantidad de unidades vendidas, y usar el target que no seleccionen como feature en su modelo.\n",
    "\n",
    "**NOTA:** No pidan más de 10000 datos totales para no tener conflictos con los límites de la API, no pidan menos de 500 para poder modelar de forma sencilla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importamos los datos\n",
    "\n",
    "Vamos a usar esta celda con un input para poder ingresar manualmente la búsqueda que hicimos en la práctica anterior. La búsqueda puede ser cualquier producto que les resulte interesante, sólo recuerden usar el mismo que usaron para generar el dataset!\n",
    "\n",
    "Ejemplo: iphone 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lectura del DataFrame\n",
    "search = input(\"Inserten la búsqueda utilizada para generar el DataFrame:\")\n",
    "df = pd.read_csv(f\"../Data/{search.lower().replace(' ', '_')}_meli.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identificamos columnas numéricas y categóricas\n",
    "\n",
    "El objetivo de este ejercicio es seleccionar columnas categóricas y numéricas. Vamos a identificarlas, de manera de poder armar un preprocesamiento acorde para cada una. **BONUS:** Identificar columnas de texto y pensar una solución que incluya text mining para nuestro pipeline final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Planteamos la FeatureUnion para nuestras distintas variables\n",
    "\n",
    "Armemos un Pipeline de preprocesamiento para cada tipo de variable, y usemos FeatureUnion para unir los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Armamos nuestro Pipeline\n",
    "\n",
    "Generemos un Pipeline que tome como paso el FeatureUnion del ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Utilizamos Gridsearch para tunear hiperparámetros\n",
    "Vamos a terminar esta práctica haciendo un tuneo para el Pipeline final. Intentemos maximizar nuestro $R^2$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
